{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5bfb89da",
   "metadata": {},
   "source": [
    "---\n",
    "self-contained: true\n",
    "title: \"Leveraging Keras Neural Networks to Detect Diabetes\"\n",
    "author: \"Riley Svensson\"\n",
    "format:\n",
    "    html:\n",
    "        theme: journal\n",
    "        toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3711037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages and potential data science tools like pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from imblearn.pipeline import Pipeline as ImblearnPipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPRegressor,MLPClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, ComplementNB\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from scikeras.wrappers import KerasRegressor, KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0b814",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Neural Networks are a fundamental aspect of deep learning, capable of modeling complex relationships in data.  In this lab, we aimed to predict the presence of diabetes using data from the Centers for Disease Control and Prevention (CDC), specifically the Behavioral Risk Factor Surveillance System (BRFSS). Our primary goal was to build and evaluate various neural network models to determine their effectiveness in binary classification for predicting diabetes, and compare their performance to any other best method we have utilized.  To allow for a controlled comparison in usage and performance metrics of two differing models, I chose to utilize the balanced dataset with 50% of cases each having diabetes and not, which does not give an unfair advantage to methods that are well-versed in handling imbalanced like XGBoost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c528aa6",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40d64905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in the data, naming our df in context\n",
    "diabetes_data = pd.read_csv(\"/Users/rileysvensson/Desktop/GSB 545 - Advanced Machine Learning/archive (4)/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fe99e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GeneralHealth_Rating</th>\n",
       "      <th>PoorGenHealth_Days</th>\n",
       "      <th>PoorPhysHealth_Days</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           1.0     0.0  ...            1.0   \n",
       "1                   0.0           0.0     1.0  ...            1.0   \n",
       "2                   0.0           1.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GeneralHealth_Rating  PoorGenHealth_Days  PoorPhysHealth_Days  \\\n",
       "0          0.0                   3.0                 5.0                 30.0   \n",
       "1          0.0                   3.0                 0.0                  0.0   \n",
       "2          0.0                   1.0                 0.0                 10.0   \n",
       "3          0.0                   3.0                 0.0                  3.0   \n",
       "4          0.0                   2.0                 0.0                  0.0   \n",
       "\n",
       "   DiffWalk  Sex   Age  Education  Income  \n",
       "0       0.0  1.0   4.0        6.0     8.0  \n",
       "1       0.0  1.0  12.0        6.0     8.0  \n",
       "2       0.0  1.0  13.0        6.0     8.0  \n",
       "3       0.0  1.0  11.0        6.0     8.0  \n",
       "4       0.0  0.0   8.0        5.0     8.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When viewing the data it displays a very clean set with pre-scaled values for income and other features\n",
    "\n",
    "# Check for missing values before modeling, displaying no issues \n",
    "diabetes_data.isnull().sum()\n",
    "\n",
    "# Renaming a few variables to be more descriptive of the column \n",
    "diabetes_data.rename(columns={ 'MentHlth': 'PoorGenHealth_Days', 'PhysHlth': 'PoorPhysHealth_Days',\n",
    "                                'GenHlth': 'GeneralHealth_Rating'}, inplace=True)\n",
    "\n",
    "# Define column transformer to be used for preprocessing \n",
    "ct_all = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\" \n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "# View head of the data to prepare for modeling\n",
    "diabetes_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c605c4",
   "metadata": {},
   "source": [
    "This dataset required no cleaning or pre-processing due to its completeness and perfectly balanced target variable, Binary Diabetes, which allowed me to focus on understanding the effects of various features within our models. Before modeling, I sought to contextualize the growing issue of diabetes in the US, aiming to confirm hypotheses and previous findings with current data. Given the large potential feature set, it is optimal to identify and remove features that have no effect on a person's diabetes status. To research this, I visited the CDC's page on diabetes risk factors to confirm key influences on diabetes. The CDC warns that diabetes is more prevalent among elderly and overweight individuals, and those with family history risks (not captured in our variables). The relevant predictors in our dataset include `Age`, `HighChol`, `HighBP`, `PhysActivity`, `BMI` and `General Health`.\n",
    "\n",
    "To understand these factors true predictive affect on if a patient has Diabetes or not, we can leverage an initial Logistic Regression model, to return the slope's or overall impact that each predictor has on Diabetes.  Logistic regression relies on the use of probabilities to predict a case of diabetes as 1 or 0, based on a percentage likelihood cutoff which is typically 0.50.  Along with this logistic model, we created a few interaction terms to test for any additional significant relationships between variables like Income and HighBP, as it could be expected that high income individuals have more income in which they are able to spend on healthy food, exercise memberships, and therefore better overall health (less risk for Diabetes). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d586bb87",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a452f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'logisticregressor__C': 10, 'logisticregressor__penalty': 'l2'}\n",
      "Best accuracy:  0.7462816647687838\n",
      "Test set accuracy:  0.7506601282534893\n"
     ]
    }
   ],
   "source": [
    "# Drop 'Diabetes_binary' as the target column\n",
    "X = diabetes_data.drop('Diabetes_binary', axis=1)\n",
    "y = diabetes_data['Diabetes_binary']\n",
    "\n",
    "# Create interaction terms\n",
    "diabetes_data['Income_BMI'] = diabetes_data['Income'] * diabetes_data['BMI']\n",
    "diabetes_data['Income_HighBP'] = diabetes_data['Income'] * diabetes_data['HighBP']\n",
    "diabetes_data['Income_HighChol'] = diabetes_data['Income'] * diabetes_data['HighChol']\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "# Using ct_all which is already defined\n",
    "logistic_regression_pipeline = Pipeline([\n",
    "    (\"preprocessor\", ct_all),\n",
    "    (\"logisticregressor\", LogisticRegression(max_iter=1000, solver='lbfgs'))\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'logisticregressor__C': [0.1, 1, 10], \n",
    "    'logisticregressor__penalty': ['l2'] \n",
    "}\n",
    "\n",
    "# Tuning with GridSearchCV, using 'accuracy' as the scoring metric for classification\n",
    "grid_search = GridSearchCV(logistic_regression_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best accuracy: \", grid_search.best_score_)\n",
    "\n",
    "# Re-predict on the test set\n",
    "test_predictions = grid_search.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test set accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f541a",
   "metadata": {},
   "source": [
    "## Feature Effect Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9480d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.525569\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Diabetes_binary</td> <th>  No. Observations:  </th>  <td> 49484</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 49459</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 13 May 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.2418</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:25:56</td>     <th>  Log-Likelihood:    </th> <td> -26007.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -34300.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HighBP</th>               <td>    0.3802</td> <td>    0.065</td> <td>    5.808</td> <td> 0.000</td> <td>    0.252</td> <td>    0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HighChol</th>             <td>    0.3451</td> <td>    0.062</td> <td>    5.532</td> <td> 0.000</td> <td>    0.223</td> <td>    0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CholCheck</th>            <td>    0.1534</td> <td>    0.071</td> <td>    2.175</td> <td> 0.030</td> <td>    0.015</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>                  <td>   -0.0359</td> <td>    0.003</td> <td>  -12.185</td> <td> 0.000</td> <td>   -0.042</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Smoker</th>               <td>   -0.0686</td> <td>    0.022</td> <td>   -3.095</td> <td> 0.002</td> <td>   -0.112</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stroke</th>               <td>    0.1671</td> <td>    0.049</td> <td>    3.439</td> <td> 0.001</td> <td>    0.072</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HeartDiseaseorAttack</th> <td>    0.3411</td> <td>    0.034</td> <td>   10.146</td> <td> 0.000</td> <td>    0.275</td> <td>    0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PhysActivity</th>         <td>   -0.1070</td> <td>    0.025</td> <td>   -4.304</td> <td> 0.000</td> <td>   -0.156</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruits</th>               <td>   -0.2847</td> <td>    0.060</td> <td>   -4.738</td> <td> 0.000</td> <td>   -0.403</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Veggies</th>              <td>   -0.1167</td> <td>    0.027</td> <td>   -4.259</td> <td> 0.000</td> <td>   -0.170</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HvyAlcoholConsump</th>    <td>   -0.8249</td> <td>    0.058</td> <td>  -14.256</td> <td> 0.000</td> <td>   -0.938</td> <td>   -0.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AnyHealthcare</th>        <td>   -0.2903</td> <td>    0.054</td> <td>   -5.413</td> <td> 0.000</td> <td>   -0.395</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NoDocbcCost</th>          <td>   -0.1569</td> <td>    0.039</td> <td>   -4.050</td> <td> 0.000</td> <td>   -0.233</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GeneralHealth_Rating</th> <td>    0.4574</td> <td>    0.013</td> <td>   35.279</td> <td> 0.000</td> <td>    0.432</td> <td>    0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PoorGenHealth_Days</th>   <td>   -0.0071</td> <td>    0.001</td> <td>   -4.746</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PoorPhysHealth_Days</th>  <td>   -0.0028</td> <td>    0.001</td> <td>   -1.999</td> <td> 0.046</td> <td>   -0.006</td> <td>-5.39e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DiffWalk</th>             <td>    0.1953</td> <td>    0.030</td> <td>    6.433</td> <td> 0.000</td> <td>    0.136</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex</th>                  <td>    0.1945</td> <td>    0.023</td> <td>    8.626</td> <td> 0.000</td> <td>    0.150</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>                  <td>    0.1065</td> <td>    0.004</td> <td>   24.266</td> <td> 0.000</td> <td>    0.098</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Education</th>            <td>   -0.1420</td> <td>    0.012</td> <td>  -12.197</td> <td> 0.000</td> <td>   -0.165</td> <td>   -0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income</th>               <td>   -0.6790</td> <td>    0.018</td> <td>  -37.509</td> <td> 0.000</td> <td>   -0.715</td> <td>   -0.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income_BMI</th>           <td>    0.0172</td> <td>    0.001</td> <td>   29.682</td> <td> 0.000</td> <td>    0.016</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income_HighBP</th>        <td>    0.0699</td> <td>    0.011</td> <td>    6.575</td> <td> 0.000</td> <td>    0.049</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income_HighChol</th>      <td>    0.0472</td> <td>    0.010</td> <td>    4.599</td> <td> 0.000</td> <td>    0.027</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income_Fruit</th>         <td>    0.0438</td> <td>    0.010</td> <td>    4.394</td> <td> 0.000</td> <td>    0.024</td> <td>    0.063</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}        & Diabetes\\_binary & \\textbf{  No. Observations:  } &    49484    \\\\\n",
       "\\textbf{Model:}                &      Logit       & \\textbf{  Df Residuals:      } &    49459    \\\\\n",
       "\\textbf{Method:}               &       MLE        & \\textbf{  Df Model:          } &       24    \\\\\n",
       "\\textbf{Date:}                 & Mon, 13 May 2024 & \\textbf{  Pseudo R-squ.:     } &   0.2418    \\\\\n",
       "\\textbf{Time:}                 &     14:25:56     & \\textbf{  Log-Likelihood:    } &   -26007.   \\\\\n",
       "\\textbf{converged:}            &       True       & \\textbf{  LL-Null:           } &   -34300.   \\\\\n",
       "\\textbf{Covariance Type:}      &    nonrobust     & \\textbf{  LLR p-value:       } &    0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{HighBP}                &       0.3802  &        0.065     &     5.808  &         0.000        &        0.252    &        0.509     \\\\\n",
       "\\textbf{HighChol}              &       0.3451  &        0.062     &     5.532  &         0.000        &        0.223    &        0.467     \\\\\n",
       "\\textbf{CholCheck}             &       0.1534  &        0.071     &     2.175  &         0.030        &        0.015    &        0.292     \\\\\n",
       "\\textbf{BMI}                   &      -0.0359  &        0.003     &   -12.185  &         0.000        &       -0.042    &       -0.030     \\\\\n",
       "\\textbf{Smoker}                &      -0.0686  &        0.022     &    -3.095  &         0.002        &       -0.112    &       -0.025     \\\\\n",
       "\\textbf{Stroke}                &       0.1671  &        0.049     &     3.439  &         0.001        &        0.072    &        0.262     \\\\\n",
       "\\textbf{HeartDiseaseorAttack}  &       0.3411  &        0.034     &    10.146  &         0.000        &        0.275    &        0.407     \\\\\n",
       "\\textbf{PhysActivity}          &      -0.1070  &        0.025     &    -4.304  &         0.000        &       -0.156    &       -0.058     \\\\\n",
       "\\textbf{Fruits}                &      -0.2847  &        0.060     &    -4.738  &         0.000        &       -0.403    &       -0.167     \\\\\n",
       "\\textbf{Veggies}               &      -0.1167  &        0.027     &    -4.259  &         0.000        &       -0.170    &       -0.063     \\\\\n",
       "\\textbf{HvyAlcoholConsump}     &      -0.8249  &        0.058     &   -14.256  &         0.000        &       -0.938    &       -0.711     \\\\\n",
       "\\textbf{AnyHealthcare}         &      -0.2903  &        0.054     &    -5.413  &         0.000        &       -0.395    &       -0.185     \\\\\n",
       "\\textbf{NoDocbcCost}           &      -0.1569  &        0.039     &    -4.050  &         0.000        &       -0.233    &       -0.081     \\\\\n",
       "\\textbf{GeneralHealth\\_Rating} &       0.4574  &        0.013     &    35.279  &         0.000        &        0.432    &        0.483     \\\\\n",
       "\\textbf{PoorGenHealth\\_Days}   &      -0.0071  &        0.001     &    -4.746  &         0.000        &       -0.010    &       -0.004     \\\\\n",
       "\\textbf{PoorPhysHealth\\_Days}  &      -0.0028  &        0.001     &    -1.999  &         0.046        &       -0.006    &    -5.39e-05     \\\\\n",
       "\\textbf{DiffWalk}              &       0.1953  &        0.030     &     6.433  &         0.000        &        0.136    &        0.255     \\\\\n",
       "\\textbf{Sex}                   &       0.1945  &        0.023     &     8.626  &         0.000        &        0.150    &        0.239     \\\\\n",
       "\\textbf{Age}                   &       0.1065  &        0.004     &    24.266  &         0.000        &        0.098    &        0.115     \\\\\n",
       "\\textbf{Education}             &      -0.1420  &        0.012     &   -12.197  &         0.000        &       -0.165    &       -0.119     \\\\\n",
       "\\textbf{Income}                &      -0.6790  &        0.018     &   -37.509  &         0.000        &       -0.715    &       -0.644     \\\\\n",
       "\\textbf{Income\\_BMI}           &       0.0172  &        0.001     &    29.682  &         0.000        &        0.016    &        0.018     \\\\\n",
       "\\textbf{Income\\_HighBP}        &       0.0699  &        0.011     &     6.575  &         0.000        &        0.049    &        0.091     \\\\\n",
       "\\textbf{Income\\_HighChol}      &       0.0472  &        0.010     &     4.599  &         0.000        &        0.027    &        0.067     \\\\\n",
       "\\textbf{Income\\_Fruit}         &       0.0438  &        0.010     &     4.394  &         0.000        &        0.024    &        0.063     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:        Diabetes_binary   No. Observations:                49484\n",
       "Model:                          Logit   Df Residuals:                    49459\n",
       "Method:                           MLE   Df Model:                           24\n",
       "Date:                Mon, 13 May 2024   Pseudo R-squ.:                  0.2418\n",
       "Time:                        14:25:56   Log-Likelihood:                -26007.\n",
       "converged:                       True   LL-Null:                       -34300.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "HighBP                   0.3802      0.065      5.808      0.000       0.252       0.509\n",
       "HighChol                 0.3451      0.062      5.532      0.000       0.223       0.467\n",
       "CholCheck                0.1534      0.071      2.175      0.030       0.015       0.292\n",
       "BMI                     -0.0359      0.003    -12.185      0.000      -0.042      -0.030\n",
       "Smoker                  -0.0686      0.022     -3.095      0.002      -0.112      -0.025\n",
       "Stroke                   0.1671      0.049      3.439      0.001       0.072       0.262\n",
       "HeartDiseaseorAttack     0.3411      0.034     10.146      0.000       0.275       0.407\n",
       "PhysActivity            -0.1070      0.025     -4.304      0.000      -0.156      -0.058\n",
       "Fruits                  -0.2847      0.060     -4.738      0.000      -0.403      -0.167\n",
       "Veggies                 -0.1167      0.027     -4.259      0.000      -0.170      -0.063\n",
       "HvyAlcoholConsump       -0.8249      0.058    -14.256      0.000      -0.938      -0.711\n",
       "AnyHealthcare           -0.2903      0.054     -5.413      0.000      -0.395      -0.185\n",
       "NoDocbcCost             -0.1569      0.039     -4.050      0.000      -0.233      -0.081\n",
       "GeneralHealth_Rating     0.4574      0.013     35.279      0.000       0.432       0.483\n",
       "PoorGenHealth_Days      -0.0071      0.001     -4.746      0.000      -0.010      -0.004\n",
       "PoorPhysHealth_Days     -0.0028      0.001     -1.999      0.046      -0.006   -5.39e-05\n",
       "DiffWalk                 0.1953      0.030      6.433      0.000       0.136       0.255\n",
       "Sex                      0.1945      0.023      8.626      0.000       0.150       0.239\n",
       "Age                      0.1065      0.004     24.266      0.000       0.098       0.115\n",
       "Education               -0.1420      0.012    -12.197      0.000      -0.165      -0.119\n",
       "Income                  -0.6790      0.018    -37.509      0.000      -0.715      -0.644\n",
       "Income_BMI               0.0172      0.001     29.682      0.000       0.016       0.018\n",
       "Income_HighBP            0.0699      0.011      6.575      0.000       0.049       0.091\n",
       "Income_HighChol          0.0472      0.010      4.599      0.000       0.027       0.067\n",
       "Income_Fruit             0.0438      0.010      4.394      0.000       0.024       0.063\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit the logistic regression model using stats models function\n",
    "model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "# Print the summary of the model to see the coefficients and p-values\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c02a64",
   "metadata": {},
   "source": [
    "In terms of factors associated with Diabetes, we can look into the summary results of our Logistic Regression model, typically utilized when predicting a binary (2 categories) target variable.  The statsmodels package within Python allows us to easily refer to logistic regression summary statistics, providing additional information beyond simple slope coefficient's, such as p-values and confidence intervals.  Based on these predictive effects, we can see that every one has a significant impact on Diabetes status, when applying an alpha level or significance threshold of 0.05.  After running a few different iterations, I noticed slightly differing results in terms of statistical significance within the variables `CholCheck` and `PoorPhysicalHealthDays` showing an insigificant impact at times.  To account for this variability, I elected to use a higher p-value cutoff than 0.05, of 0.01, which warrented me to remove these insignifcant variables with p-values of 0.046 and 0.03.  In terms of our tested interactions, all of which result in statistically significant p-values, indicating that they contribute meaningfully to the model, beyond the main effects of the individual variables. \n",
    "\n",
    "However, it is interesting to interpret the slope coefficient of our interactions, to ensure that we can explain and udnerstand the underlying impact of each interaction on our target variable, Diabtes.  The positive coefficient's for all three interaction term's: `Income_BMI`, `Income_HighBP`, and `Income_HighChol`, indicate that as both BMI and income increase, the combined effect on the likelihood of diabetes increases. This may seem counterintuitive from our hypothesis earlier, however there are several factors that could explain this relationship. First off, higher income individuals might have better access to healthcare and therefore are more likely to be diagnosed with diabetes if they have a high BMI/Chol/BP. Additionally, higher income does not necessarily equate to healthier lifestyle choices, as people with higher incomes might have more opportunities to indulge in behaviors that contribute to higher BMI/Chol/BP, such as eating out frequently or consuming high-calorie foods.  Now that we understand the significant factors that contribute to diabetes, we can move into modeling with more complex solutions like Keras' Neural Networks and Stacking Model's to improve our decent accuracy of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883b3de",
   "metadata": {},
   "source": [
    "## Model 1: Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef0cba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step - accuracy: 0.7203 - loss: 0.5413\n",
      "Epoch 2/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7484 - loss: 0.5074\n",
      "Epoch 3/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233us/step - accuracy: 0.7540 - loss: 0.5035\n",
      "Epoch 4/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235us/step - accuracy: 0.7543 - loss: 0.5033\n",
      "Epoch 5/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7513 - loss: 0.5044\n",
      "Epoch 6/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233us/step - accuracy: 0.7544 - loss: 0.5021\n",
      "Epoch 7/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233us/step - accuracy: 0.7525 - loss: 0.5054\n",
      "Epoch 8/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236us/step - accuracy: 0.7540 - loss: 0.5032\n",
      "Epoch 9/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235us/step - accuracy: 0.7496 - loss: 0.5061\n",
      "Epoch 10/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7528 - loss: 0.5029\n",
      "Epoch 11/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7568 - loss: 0.4983\n",
      "Epoch 12/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7573 - loss: 0.4998\n",
      "Epoch 13/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7560 - loss: 0.4974\n",
      "Epoch 14/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233us/step - accuracy: 0.7542 - loss: 0.5012\n",
      "Epoch 15/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235us/step - accuracy: 0.7566 - loss: 0.4983\n",
      "Epoch 16/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7562 - loss: 0.5035\n",
      "Epoch 17/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step - accuracy: 0.7548 - loss: 0.5013\n",
      "Epoch 18/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234us/step - accuracy: 0.7563 - loss: 0.4990\n",
      "Epoch 19/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232us/step - accuracy: 0.7537 - loss: 0.4984\n",
      "Epoch 20/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233us/step - accuracy: 0.7555 - loss: 0.5010\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178us/step - accuracy: 0.7537 - loss: 0.5016\n",
      "Test accuracy: 0.751791775226593\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Preprocess the data\n",
    "\n",
    "# Drop 'Diabetes_binary' due to it being our target column & drop insignificant predictors\n",
    "X = diabetes_data.drop(['Diabetes_binary','PoorPhysHealth_Days', 'CholCheck'], axis=1)\n",
    "y = diabetes_data['Diabetes_binary']\n",
    "\n",
    "# Normalize features using a standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Specify numbers of features which will be used for the input shape \n",
    "number_of_features = len(X.columns)\n",
    "\n",
    "# Step 2: Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=(number_of_features,)),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9914bd6f",
   "metadata": {},
   "source": [
    "## Model 2: Keras Neural Network - Feature Selection & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d568d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 326us/step - accuracy: 0.7161 - loss: 0.5586\n",
      "Epoch 2/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324us/step - accuracy: 0.7508 - loss: 0.5185\n",
      "Epoch 3/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325us/step - accuracy: 0.7457 - loss: 0.5182\n",
      "Epoch 4/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323us/step - accuracy: 0.7491 - loss: 0.5144\n",
      "Epoch 5/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322us/step - accuracy: 0.7499 - loss: 0.5116\n",
      "Epoch 6/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322us/step - accuracy: 0.7523 - loss: 0.5095\n",
      "Epoch 7/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320us/step - accuracy: 0.7490 - loss: 0.5144\n",
      "Epoch 8/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323us/step - accuracy: 0.7517 - loss: 0.5100\n",
      "Epoch 9/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321us/step - accuracy: 0.7537 - loss: 0.5069\n",
      "Epoch 10/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 326us/step - accuracy: 0.7492 - loss: 0.5133\n",
      "Epoch 11/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321us/step - accuracy: 0.7510 - loss: 0.5086\n",
      "Epoch 12/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323us/step - accuracy: 0.7506 - loss: 0.5134\n",
      "Epoch 13/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322us/step - accuracy: 0.7509 - loss: 0.5089\n",
      "Epoch 14/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321us/step - accuracy: 0.7477 - loss: 0.5121\n",
      "Epoch 15/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322us/step - accuracy: 0.7495 - loss: 0.5093\n",
      "Epoch 16/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329us/step - accuracy: 0.7538 - loss: 0.5060\n",
      "Epoch 17/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324us/step - accuracy: 0.7550 - loss: 0.5056\n",
      "Epoch 18/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322us/step - accuracy: 0.7520 - loss: 0.5078\n",
      "Epoch 19/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324us/step - accuracy: 0.7516 - loss: 0.5064\n",
      "Epoch 20/20\n",
      "\u001b[1m4949/4949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325us/step - accuracy: 0.7512 - loss: 0.5083\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190us/step - accuracy: 0.7539 - loss: 0.5055\n",
      "Test accuracy: 0.7530648708343506\n"
     ]
    }
   ],
   "source": [
    "# Specify numbers of features which will be used for the input shape \n",
    "number_of_features = len(X.columns)\n",
    "\n",
    "# Step 2: Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=(number_of_features,)),\n",
    "    Dense(64, activation='relu'),      # Increased neurons\n",
    "    Dropout(0.3),                   \n",
    "    Dense(32, activation='relu'),  \n",
    "    Dropout(0.3),                     # Dropout used to apply regularization\n",
    "    Dense(16, activation='relu'),   \n",
    "    Dropout(0.3),                      # Added more dense layer's\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7404071",
   "metadata": {},
   "source": [
    "Following the removal of insignificant variables found during exploratory logistic regression and the addition of more neural network layers, parameters and regularization with dropout, our accuracy rate of 75% still showed almost no change suggesting a maximum.  **Even then, an accuracy of above 70% in practical data sources suggest a highly successful model, that can have many usages within hospital, personal, and even insurance contexts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ea5e3",
   "metadata": {},
   "source": [
    "## Model 3 - Stacked Model \n",
    "\n",
    "1. Base Models - XgBoost, AdaBoost, MLPClassifier, Random Forest\n",
    "2. Final Meta-Model - Logistic Regression\n",
    "\n",
    "In this ensemble approach, we have built the following base models (XgBoost, AdaBoost, MLPClassifier, and Random Forest) each contribute to making initial predictions. These models are selected for their diverse strengths in handling different types of data and capturing various patterns. The predictions from these base models are then used as inputs for the final meta-model, which in this case is Logistic Regression. The Logistic Regression model synthesizes these inputs to produce a final prediction, leveraging the combined knowledge of the base models to enhance overall performance and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c03be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Test Accuracy: 0.7533477932855526\n"
     ]
    }
   ],
   "source": [
    "# Drop 'Diabetes_binary' due to it being our target column & drop insignificant predictors\n",
    "X = diabetes_data.drop(['Diabetes_binary', 'PoorPhysHealth_Days', 'CholCheck'], axis=1)\n",
    "y = diabetes_data['Diabetes_binary']\n",
    "\n",
    "# Define column transformer to be used for preprocessing\n",
    "ct_all = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "     make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder=\"passthrough\"\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "# Apply the column transformer to the entire dataset\n",
    "X_preprocessed = ct_all.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define base models within the preprocessing pipeline and tuned parameteres with usual best performers\n",
    "base_models = [\n",
    "    ('gradient_boosting', Pipeline([\n",
    "        ('classifier', GradientBoostingClassifier(learning_rate=0.1, max_depth=4, n_estimators=300))\n",
    "    ])),\n",
    "    ('xgbboost', Pipeline([\n",
    "        ('classifier', XGBClassifier(learning_rate = 0.3, max_depth = 4, n_estimators = 300))\n",
    "    ])), \n",
    "    ('mlp_classifier', Pipeline([\n",
    "        ('preprocessor', ct_all),\n",
    "        ('classifier', MLPClassifier(activation = 'relu', hidden_layer_sizes = (100,), \n",
    "                                     learning_rate = 'constant', solver = 'adam', max_iter = 1000,\n",
    "                                     early_stopping = True))\n",
    "    ])),\n",
    "    ('ada_boost', Pipeline([\n",
    "        ('classifier', AdaBoostClassifier(algorithm ='SAMME', n_estimators = 300,\n",
    "                                          learning_rate = 0.1 ))\n",
    "     ])),\n",
    "    ('random_forest', Pipeline([\n",
    "        ('classifier', RandomForestClassifier(max_depth = None, min_samples_leaf = 1,\n",
    "                                              n_estimators = 150))\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# Define the final regressor method, typically Linear or Logistic, in this case for classification use Log\n",
    "final_regressor = LogisticRegression()\n",
    "\n",
    "# Create the stacking ensemble\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=final_regressor, cv=5)\n",
    "\n",
    "# Fit the stacking model on train data\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict/evaluate the model on Test data\n",
    "stacking_predictions = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "\n",
    "# Stacking model performance including final feature set\n",
    "print(\"Stacking Model Test Accuracy:\", stacking_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2830c968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix, using labels from the classifier\n",
    "labels = stacking_classifier.classes_ \n",
    "cm = confusion_matrix(y_test, stacking_predictions, labels=labels)\n",
    "\n",
    "# Plotting the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sn.heatmap(cm, annot=True, cmap='Blues', cbar=True, fmt='d',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix for Stacking Classifier')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('Actual Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ab5cf",
   "metadata": {},
   "source": [
    "## Discussion of Results \n",
    "\n",
    "Its no suprise that the Stacking Model achieved the highest a test accuracy of 75.33%, while both the Keras Neural Network and Logistic Regression models came in closely behind with a test accuracy of 75.30% and 75%.  However this was far closer in performance that we typically see between methods, and in this case the final meta-model was unable to learn significantly more than even a simple logistic regression. These consistent results were expected with the clean and well-preprocessed data, alowing us to effectively capture the underlying patterns related to diabetes prediction. When examining the factors associated with diabetes, the Logistic Regression model revealed some interesting insights. **Factors positively associated with diabetes include high blood pressure, high cholesterol, stroke history, heart disease, poor general health rating, difficulty walking, being male, and older age, mostly all of which are obvious aside from gender.** On the flip side, variables **negatively associated with diabetes are BMI, physical activity, fruit and vegetable consumption, access to healthcare, education, and higher income.**  The remaining factors within the model, although statistically significant, were likely unaffecting of having diabetes, while the features discussed above had high z-scores as well, meaning that they have a large effect.  It was surprising to find that being a smoker has seemingly no effect on diabetes status, along with poor physical health days which could be random or self-inflicted. \n",
    "\n",
    "Once again, the interaction terms (`Income_BMI`, `Income_HighBP`, and `Income_HighChol`) showed a positive association with diabetes, which suggests that as both BMI and income increase, the likelihood of diabetes also rises. This might seem counterintuitive initially, but makes sense when you consider that higher-income individuals might have better access to healthcare, leading to more frequent diabetes diagnoses if they have high BMI, cholesterol, or blood pressure. Additionally, people with higher incomes might indulge more in eating out and consuming high-calorie foods, contributing to higher BMI, cholesterol, or blood pressure, and thus increasing their risk of diabetes. Finally, when inspecting the final confusion matrix of our stacking model predictions, we are able to visualize our success, correctly predicting 8,405 diabetic cases and 7,572 non-diabetics. **In terms of the cost of misclassifications, our model aims at minimizing the false negatives in which we predict someone to be clear of diabetes risk, when they will eventually develop it or have it already requiring treatment.  In this case, our false negatives are 2,202 which is a large value but in context serves as our smallest cases of a prediction group (TP, FP, TN, FN) which is a good sign.** We incorrectly predicted 3,029 people to have diabetes when they did not, however this likely means that these individuals share similar traits as diabetic's, indicating that they should be monitored and practice the negatively associated factors above that can be controlled.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3eefdf",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "[Diabetes Risk Factors - CDC](https://www.cdc.gov/diabetes/basics/risk-factors.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
